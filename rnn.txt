
=== Learning RNN identity for dimension = 8 ===

=== Epoch 500 ===
loss = 0.00091445
learning rate = 0.05000000
Absolute performance:
max abs err = 0.15508157
mean abs err = 0.00877329

=== Epoch 1000 ===
loss = 0.00060710
learning rate = 0.02500000
Absolute performance:
max abs err = 0.11647421
mean abs err = 0.00793693

=== Epoch 1500 ===
loss = 0.00000005
learning rate = 0.01250000
Absolute performance:
max abs err = 0.00130743
mean abs err = 0.00009195

=== Epoch 2000 ===
loss = 0.00000000
learning rate = 0.00625000
Absolute performance:
max abs err = 0.00010598
mean abs err = 0.00000545

=== Epoch 2500 ===
loss = 0.00000000
learning rate = 0.00312500
Absolute performance:
max abs err = 0.00002736
mean abs err = 0.00000131

After 2500 epochs (0:00:13 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 0.9847,  0.7330,  0.6674, -0.1832, -0.1817,  0.0441,  1.4733,  0.1855],
        [ 0.4569,  0.0433,  0.1189, -0.4373, -0.0235, -0.2210, -0.6507,  0.3610],
        [ 0.2723,  0.3467,  1.1071,  0.2282,  0.1351,  0.0118, -0.1021,  0.1073],
        [-0.1561, -0.5117, -0.1891,  1.0357,  0.3747,  0.9811,  0.5582, -0.0768],
        [ 0.0220, -0.2952,  0.5028, -0.0392,  0.5003, -0.1710,  0.0142, -0.0853],
        [ 0.1171,  0.0405, -0.1153,  0.3444, -0.7248,  0.3889, -0.0897,  0.2589],
        [ 0.5422, -0.5320, -0.4217,  0.3168,  0.1307, -0.4293,  0.3136,  0.0472],
        [ 0.8123,  0.3502, -0.5389,  0.6866, -0.3628,  0.6932, -0.1018,  0.7035]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-3.1976e-01,  6.0809e-01, -1.2068e-01,  2.2341e-01,  1.6742e-01,
          5.4103e-01,  1.1770e-01, -4.3651e-01],
        [ 1.2644e-01, -2.0128e-02, -3.5880e-01,  9.5398e-02,  6.2888e-01,
          2.4158e-03,  3.8695e-01, -4.1267e-02],
        [-1.8987e-01,  6.9490e-01, -1.3382e-01,  4.6712e-01,  5.5427e-01,
          1.9513e-01, -2.3622e-01, -1.9639e-01],
        [ 8.7475e-01, -1.9384e-01, -1.9241e-01, -8.1604e-02, -2.6969e-01,
         -3.1697e-04,  6.1463e-01, -3.6278e-01],
        [ 2.2358e-01, -4.9039e-01,  2.0953e-01, -9.0222e-02, -2.3610e-01,
         -1.8803e-01, -3.9961e-01,  5.6140e-02],
        [-5.2218e-01,  8.5072e-02, -1.8001e-01,  6.9475e-01,  1.2910e-02,
         -9.6953e-02, -2.3538e-01, -3.9565e-01],
        [-9.0644e-03, -5.7995e-02, -4.3745e-01, -6.7719e-02,  7.8169e-01,
         -5.9737e-02, -1.6675e-01,  1.3665e-01],
        [ 3.6636e-01, -1.2360e-01,  7.8977e-01, -9.6044e-02,  6.3725e-01,
          3.4111e-01, -7.9856e-01, -1.6403e-01]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 0.2956,  0.5336, -0.2765, -0.0053,  0.0152,  0.1084,  0.2231,  0.1064],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.2515,  0.0993,  0.0562,  0.2116, -0.0076, -0.0837, -0.0782, -0.3094],
       device='cuda:0', requires_grad=True)]

=== Learning RNN identity for dimension = 32 ===

=== Epoch 500 ===
loss = 0.00000010
learning rate = 0.00700000
Absolute performance:
max abs err = 0.00352395
mean abs err = 0.00004644

=== Epoch 1000 ===
loss = 0.00000001
learning rate = 0.00490000
Absolute performance:
max abs err = 0.00109988
mean abs err = 0.00000983

=== Epoch 1500 ===
loss = 0.00000000
learning rate = 0.00343000
Absolute performance:
max abs err = 0.00041866
mean abs err = 0.00000333

=== Epoch 2000 ===
loss = 0.00000000
learning rate = 0.00240100
Absolute performance:
max abs err = 0.00017440
mean abs err = 0.00000132

=== Epoch 2500 ===
loss = 0.00000000
learning rate = 0.00168070
Absolute performance:
max abs err = 0.00007856
mean abs err = 0.00000058

=== Epoch 3000 ===
loss = 0.00000000
learning rate = 0.00117649
Absolute performance:
max abs err = 0.00003803
mean abs err = 0.00000029

=== Epoch 3500 ===
loss = 0.00000000
learning rate = 0.00082354
Absolute performance:
max abs err = 0.00001979
mean abs err = 0.00000017

After 3500 epochs (0:00:17 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 0.2623,  0.0247,  0.2165,  ..., -0.2211, -0.1131,  0.2301],
        [ 0.2651,  0.1351,  0.0700,  ...,  0.0132,  0.1282,  0.0648],
        [-0.0044,  0.0612,  0.2864,  ..., -0.1263,  0.2309,  0.1925],
        ...,
        [-0.1014, -0.1968, -0.0230,  ...,  0.2943, -0.1861,  0.1585],
        [ 0.0287,  0.1230,  0.2509,  ..., -0.1863,  0.0014,  0.0536],
        [ 0.0517, -0.0279,  0.0509,  ..., -0.0340,  0.1060,  0.1597]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.3403, -0.2085,  0.0656,  ..., -0.0965, -0.0363,  0.2012],
        [ 0.1262, -0.0382,  0.1230,  ..., -0.0528,  0.0585,  0.1294],
        [-0.0200, -0.2308,  0.0033,  ..., -0.3332, -0.0761,  0.1279],
        ...,
        [ 0.1962,  0.0707,  0.0751,  ...,  0.1299, -0.1177, -0.1334],
        [ 0.0992, -0.1730, -0.0454,  ...,  0.1026, -0.1072,  0.1133],
        [ 0.1941, -0.0767,  0.1109,  ...,  0.0152, -0.1644, -0.0443]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0822,  0.0163, -0.0422, -0.2472, -0.0289,  0.0693,  0.1122,  0.0014,
        -0.0780,  0.1802, -0.0512, -0.1382, -0.1394, -0.0116,  0.0268, -0.0322,
        -0.1323, -0.0014,  0.1154,  0.1908,  0.0024, -0.0786, -0.0781,  0.1011,
        -0.0481, -0.0360, -0.1769,  0.0797, -0.2433,  0.0452,  0.2556,  0.0041],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.1112,  0.1361,  0.0871, -0.0931,  0.1722, -0.0632, -0.0687, -0.0412,
        -0.0281,  0.1650, -0.0488, -0.0189, -0.0993,  0.0457, -0.0620,  0.1586,
        -0.0505,  0.1986, -0.0981,  0.0598,  0.0140, -0.0117,  0.0019,  0.1104,
         0.0832, -0.1122, -0.1346,  0.0826,  0.0836,  0.1345,  0.1451,  0.2596],
       device='cuda:0', requires_grad=True)]

=== Learning RNN identity for dimension = 128 ===

=== Epoch 500 ===
loss = 0.00000377
learning rate = 0.00080000
Absolute performance:
max abs err = 0.02164513
mean abs err = 0.00045944

=== Epoch 1000 ===
loss = 0.00000061
learning rate = 0.00064000
Absolute performance:
max abs err = 0.01050246
mean abs err = 0.00013994

=== Epoch 1500 ===
loss = 0.00000020
learning rate = 0.00051200
Absolute performance:
max abs err = 0.00675958
mean abs err = 0.00006655

=== Epoch 2000 ===
loss = 0.00000009
learning rate = 0.00040960
Absolute performance:
max abs err = 0.00494689
mean abs err = 0.00003824

=== Epoch 2500 ===
loss = 0.00000004
learning rate = 0.00032768
Absolute performance:
max abs err = 0.00384021
mean abs err = 0.00002449

=== Epoch 3000 ===
loss = 0.00000003
learning rate = 0.00026214
Absolute performance:
max abs err = 0.00309235
mean abs err = 0.00001687

=== Epoch 3500 ===
loss = 0.00000002
learning rate = 0.00020972
Absolute performance:
max abs err = 0.00255156
mean abs err = 0.00001219

=== Epoch 4000 ===
loss = 0.00000001
learning rate = 0.00016777
Absolute performance:
max abs err = 0.00214148
mean abs err = 0.00000914

=== Epoch 4500 ===
loss = 0.00000001
learning rate = 0.00013422
Absolute performance:
max abs err = 0.00181973
mean abs err = 0.00000702

=== Epoch 5000 ===
loss = 0.00000000
learning rate = 0.00010737
Absolute performance:
max abs err = 0.00156057
mean abs err = 0.00000551

=== Epoch 5500 ===
loss = 0.00000000
learning rate = 0.00008590
Absolute performance:
max abs err = 0.00134754
mean abs err = 0.00000439

=== Epoch 6000 ===
loss = 0.00000000
learning rate = 0.00006872
Absolute performance:
max abs err = 0.00116974
mean abs err = 0.00000355

=== Epoch 6500 ===
loss = 0.00000000
learning rate = 0.00005498
Absolute performance:
max abs err = 0.00101930
mean abs err = 0.00000290

=== Epoch 7000 ===
loss = 0.00000000
learning rate = 0.00004398
Absolute performance:
max abs err = 0.00089091
mean abs err = 0.00000240

=== Epoch 7500 ===
loss = 0.00000000
learning rate = 0.00003518
Absolute performance:
max abs err = 0.00078022
mean abs err = 0.00000200

=== Epoch 8000 ===
loss = 0.00000000
learning rate = 0.00002815
Absolute performance:
max abs err = 0.00068432
mean abs err = 0.00000168

=== Epoch 8500 ===
loss = 0.00000000
learning rate = 0.00002252
Absolute performance:
max abs err = 0.00060076
mean abs err = 0.00000142

=== Epoch 9000 ===
loss = 0.00000000
learning rate = 0.00001801
Absolute performance:
max abs err = 0.00052774
mean abs err = 0.00000121

=== Epoch 9500 ===
loss = 0.00000000
learning rate = 0.00001441
Absolute performance:
max abs err = 0.00046366
mean abs err = 0.00000104

=== Epoch 10000 ===
loss = 0.00000000
learning rate = 0.00001153
Absolute performance:
max abs err = 0.00040722
mean abs err = 0.00000089

=== Epoch 10500 ===
loss = 0.00000000
learning rate = 0.00000922
Absolute performance:
max abs err = 0.00035763
mean abs err = 0.00000077

=== Epoch 11000 ===
loss = 0.00000000
learning rate = 0.00000738
Absolute performance:
max abs err = 0.00031388
mean abs err = 0.00000068

=== Epoch 11500 ===
loss = 0.00000000
learning rate = 0.00000590
Absolute performance:
max abs err = 0.00027531
mean abs err = 0.00000059

=== Epoch 12000 ===
loss = 0.00000000
learning rate = 0.00000472
Absolute performance:
max abs err = 0.00024122
mean abs err = 0.00000052

=== Epoch 12500 ===
loss = 0.00000000
learning rate = 0.00000378
Absolute performance:
max abs err = 0.00021136
mean abs err = 0.00000046

=== Epoch 13000 ===
loss = 0.00000000
learning rate = 0.00000302
Absolute performance:
max abs err = 0.00018513
mean abs err = 0.00000041

=== Epoch 13500 ===
loss = 0.00000000
learning rate = 0.00000242
Absolute performance:
max abs err = 0.00016195
mean abs err = 0.00000036

=== Epoch 14000 ===
loss = 0.00000000
learning rate = 0.00000193
Absolute performance:
max abs err = 0.00014186
mean abs err = 0.00000032

=== Epoch 14500 ===
loss = 0.00000000
learning rate = 0.00000155
Absolute performance:
max abs err = 0.00012422
mean abs err = 0.00000028

=== Epoch 15000 ===
loss = 0.00000000
learning rate = 0.00000124
Absolute performance:
max abs err = 0.00010890
mean abs err = 0.00000025

=== Epoch 15500 ===
loss = 0.00000000
learning rate = 0.00000099
Absolute performance:
max abs err = 0.00009555
mean abs err = 0.00000023

=== Epoch 16000 ===
loss = 0.00000000
learning rate = 0.00000079
Absolute performance:
max abs err = 0.00008410
mean abs err = 0.00000020

=== Epoch 16500 ===
loss = 0.00000000
learning rate = 0.00000063
Absolute performance:
max abs err = 0.00007427
mean abs err = 0.00000018

=== Epoch 17000 ===
loss = 0.00000000
learning rate = 0.00000051
Absolute performance:
max abs err = 0.00006592
mean abs err = 0.00000016

=== Epoch 17500 ===
loss = 0.00000000
learning rate = 0.00000041
Absolute performance:
max abs err = 0.00005883
mean abs err = 0.00000014

=== Epoch 18000 ===
loss = 0.00000000
learning rate = 0.00000032
Absolute performance:
max abs err = 0.00005287
mean abs err = 0.00000013

=== Epoch 18500 ===
loss = 0.00000000
learning rate = 0.00000026
Absolute performance:
max abs err = 0.00004774
mean abs err = 0.00000013

=== Epoch 19000 ===
loss = 0.00000000
learning rate = 0.00000021
Absolute performance:
max abs err = 0.00004351
mean abs err = 0.00000011

=== Epoch 19500 ===
loss = 0.00000000
learning rate = 0.00000017
Absolute performance:
max abs err = 0.00004005
mean abs err = 0.00000011

=== Epoch 20000 ===
loss = 0.00000000
learning rate = 0.00000013
Absolute performance:
max abs err = 0.00003725
mean abs err = 0.00000010

=== Epoch 20500 ===
loss = 0.00000000
learning rate = 0.00000011
Absolute performance:
max abs err = 0.00003511
mean abs err = 0.00000009

=== Epoch 21000 ===
loss = 0.00000000
learning rate = 0.00000009
Absolute performance:
max abs err = 0.00003338
mean abs err = 0.00000009

=== Epoch 21500 ===
loss = 0.00000000
learning rate = 0.00000007
Absolute performance:
max abs err = 0.00003213
mean abs err = 0.00000008

=== Epoch 22000 ===
loss = 0.00000000
learning rate = 0.00000005
Absolute performance:
max abs err = 0.00003123
mean abs err = 0.00000008

=== Epoch 22500 ===
loss = 0.00000000
learning rate = 0.00000004
Absolute performance:
max abs err = 0.00003046
mean abs err = 0.00000008

=== Epoch 23000 ===
loss = 0.00000000
learning rate = 0.00000003
Absolute performance:
max abs err = 0.00002998
mean abs err = 0.00000007

After 23000 epochs (0:01:42 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 0.0863,  0.0721,  0.0550,  ...,  0.0066, -0.0160,  0.0569],
        [ 0.0587,  0.0463, -0.0108,  ...,  0.0743,  0.0510,  0.0736],
        [-0.0230, -0.0269,  0.0278,  ..., -0.0698,  0.0183,  0.0247],
        ...,
        [ 0.0086,  0.0088, -0.0880,  ...,  0.0792,  0.0918,  0.0237],
        [-0.0335, -0.0338, -0.0224,  ..., -0.0382,  0.0624,  0.0592],
        [ 0.0152,  0.0848,  0.0887,  ...,  0.0721,  0.0749,  0.1065]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0793, -0.0100, -0.0363,  ...,  0.0143, -0.0034,  0.0303],
        [-0.0270,  0.0477, -0.0337,  ...,  0.0663, -0.0356,  0.0518],
        [-0.0547, -0.0993,  0.0320,  ..., -0.0794,  0.0219, -0.0036],
        ...,
        [-0.0099,  0.0363,  0.0286,  ...,  0.0232,  0.0020, -0.0707],
        [ 0.0305,  0.0714, -0.0362,  ..., -0.0502, -0.0090, -0.0548],
        [ 0.0318, -0.0813, -0.0041,  ...,  0.0269, -0.0508,  0.0148]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0057, -0.0170,  0.0715, -0.0253,  0.0019,  0.0161,  0.0224, -0.0074,
        -0.0788, -0.0590, -0.0838, -0.0718,  0.0578,  0.0252, -0.1027,  0.0086,
         0.0622, -0.0443, -0.0050, -0.0496,  0.0582, -0.0075,  0.0907,  0.0359,
         0.0803, -0.0420,  0.0673, -0.0322,  0.0728, -0.0313, -0.0418, -0.0659,
        -0.0618, -0.1077, -0.0636,  0.0500, -0.0192, -0.0029,  0.0591, -0.0702,
        -0.0646, -0.0703,  0.0839, -0.0641, -0.0867, -0.0136, -0.0150,  0.0866,
        -0.0423,  0.0226,  0.0504,  0.0451,  0.0740,  0.0527, -0.0802,  0.0263,
         0.0279, -0.1228,  0.0436, -0.0468,  0.0153,  0.0826,  0.0047, -0.0048,
        -0.0284, -0.0276,  0.0585,  0.0330, -0.0833, -0.0538,  0.0018,  0.0670,
         0.0676, -0.0250, -0.0488, -0.0622,  0.0174, -0.0850, -0.1236, -0.0008,
        -0.0087,  0.0322, -0.0126, -0.0071, -0.0407,  0.0681,  0.0753, -0.0004,
         0.0166, -0.0695, -0.0923, -0.0495,  0.0087,  0.0039,  0.0646,  0.0262,
        -0.0115,  0.0113,  0.0700, -0.0848,  0.0313,  0.0554, -0.0090, -0.0022,
        -0.0850,  0.0275, -0.0322,  0.0386, -0.0061,  0.0902, -0.0084,  0.0451,
         0.0283,  0.0560,  0.0401, -0.0292, -0.0071,  0.0270,  0.0012,  0.0730,
         0.0514, -0.1030,  0.0368,  0.0969,  0.0724, -0.0264,  0.0084, -0.0118],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0073,  0.0639, -0.0249, -0.0268, -0.0044,  0.0131, -0.0477, -0.0681,
         0.0421, -0.0151, -0.0384, -0.0111,  0.0115,  0.0006, -0.0022, -0.0348,
         0.0243,  0.0628, -0.0416, -0.0140, -0.0235, -0.0155, -0.0209,  0.0683,
         0.0042,  0.0396,  0.1104,  0.1025, -0.0253, -0.0171, -0.0312, -0.0176,
         0.0182,  0.0010, -0.0275,  0.0226, -0.0099,  0.0103,  0.0584, -0.0184,
        -0.0366, -0.0280,  0.0834, -0.0614, -0.0691,  0.0141,  0.0214, -0.0608,
        -0.0321,  0.0509,  0.0926,  0.0443,  0.0665, -0.0322, -0.0979, -0.0102,
         0.0303, -0.0341,  0.0149,  0.0944, -0.1109,  0.0741,  0.0424,  0.0293,
         0.0047, -0.0019,  0.0850,  0.0450, -0.0004,  0.0167, -0.0781,  0.0615,
        -0.0572, -0.0289, -0.0511, -0.0894, -0.0877, -0.0081, -0.1292,  0.0827,
        -0.0375,  0.0118,  0.0594, -0.0487,  0.0399,  0.0791, -0.0741, -0.0205,
         0.0426,  0.0945, -0.0046,  0.0317, -0.0353,  0.0527,  0.0478, -0.0258,
         0.0021,  0.0993, -0.0515,  0.0293,  0.0018,  0.0536, -0.0919, -0.0055,
         0.0574,  0.0026,  0.0225, -0.0390,  0.0465, -0.0357, -0.0553,  0.0563,
         0.0283,  0.0285,  0.0374, -0.0004, -0.0586,  0.0176,  0.0493, -0.0384,
        -0.0523, -0.0740, -0.0568,  0.0832, -0.0516,  0.0426,  0.0415, -0.0432],
       device='cuda:0', requires_grad=True)]
