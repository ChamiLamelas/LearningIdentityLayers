
=== Learning linear identity for dimension = 4 ===

=== Epoch 500 ===
loss = 0.00000000
learning rate = 0.05000000
Absolute performance:
max abs err = 0.00000006
mean abs err = 0.00000001

After 500 epochs (0:00:02 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 1.0000e+00, -4.9561e-08,  2.8644e-08,  9.2521e-09],
        [-4.8056e-09,  1.0000e+00, -3.0416e-08,  1.8484e-08],
        [-5.7916e-09, -2.4645e-09,  1.0000e+00, -1.1969e-09],
        [-5.0306e-09, -1.8762e-08, -7.7059e-09,  1.0000e+00]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 1.3672e-08, -2.6321e-08, -1.7545e-09,  1.4753e-08], device='cuda:0',
       requires_grad=True)]

=== Learning linear identity for dimension = 32 ===

=== Epoch 500 ===
loss = 0.00003221
learning rate = 0.05000000
Absolute performance:
max abs err = 0.04942966
mean abs err = 0.00153687

=== Epoch 1000 ===
loss = 0.00000000
learning rate = 0.02500000
Absolute performance:
max abs err = 0.00000155
mean abs err = 0.00000024

=== Epoch 1500 ===
loss = 0.00000000
learning rate = 0.01250000
Absolute performance:
max abs err = 0.00000072
mean abs err = 0.00000017

After 1500 epochs (0:00:02 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 0.2669, -0.0186,  0.1554,  ..., -0.1897, -0.1364,  0.2820],
        [ 0.1735,  0.1030,  0.0814,  ...,  0.0530,  0.1024,  0.0226],
        [-0.0476,  0.0913,  0.2727,  ..., -0.0799,  0.2055,  0.2013],
        ...,
        [-0.0445, -0.1368, -0.0397,  ...,  0.2190, -0.2134,  0.2193],
        [-0.0239,  0.2023,  0.2306,  ..., -0.1205, -0.0220,  0.1105],
        [ 0.0007, -0.0675, -0.0743,  ...,  0.1030, -0.0275,  0.1055]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0495,  0.0793,  0.1054, -0.2600, -0.0134,  0.0672,  0.1018, -0.0434,
        -0.0427,  0.1616,  0.0531,  0.0202,  0.0458,  0.0494,  0.0932,  0.2393,
        -0.3006, -0.0602, -0.1367,  0.1464, -0.1253, -0.1533, -0.0574,  0.1877,
        -0.0275, -0.1172, -0.0773,  0.0009, -0.2423,  0.0502,  0.2016,  0.1938],
       device='cuda:0', requires_grad=True)]

=== Learning linear identity for dimension = 256 ===

=== Epoch 500 ===
loss = 0.01497060
learning rate = 0.05000000
Absolute performance:
max abs err = 1.39411271
mean abs err = 0.05544116

=== Epoch 1000 ===
loss = 0.00000000
learning rate = 0.02500000
Absolute performance:
max abs err = 0.00000216
mean abs err = 0.00000043

=== Epoch 1500 ===
loss = 0.00000000
learning rate = 0.01250000
Absolute performance:
max abs err = 0.00000167
mean abs err = 0.00000028

=== Epoch 2000 ===
loss = 0.00000000
learning rate = 0.00625000
Absolute performance:
max abs err = 0.00000119
mean abs err = 0.00000018

=== Epoch 2500 ===
loss = 0.00000000
learning rate = 0.00312500
Absolute performance:
max abs err = 0.00000101
mean abs err = 0.00000012

=== Epoch 3000 ===
loss = 0.00000000
learning rate = 0.00156250
Absolute performance:
max abs err = 0.00000072
mean abs err = 0.00000009

After 3000 epochs (0:00:03 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 0.0409, -0.0201, -0.0069,  ...,  0.0230, -0.0143, -0.0251],
        [ 0.0444, -0.0273, -0.0257,  ...,  0.0003,  0.0078, -0.0268],
        [-0.0054,  0.0865,  0.0623,  ..., -0.0351, -0.0155,  0.0278],
        ...,
        [ 0.0467,  0.0325, -0.0224,  ...,  0.0600, -0.0061,  0.0330],
        [ 0.0366, -0.0279,  0.0229,  ...,  0.0224, -0.0448, -0.0322],
        [-0.0450, -0.0091, -0.0696,  ..., -0.0148, -0.0185,  0.0525]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0425,  0.0101,  0.0117, -0.0427,  0.0744, -0.0351, -0.0180,  0.0223,
         0.0787, -0.0736, -0.0091, -0.0261, -0.0633, -0.0498, -0.0171, -0.0562,
        -0.1369, -0.0456,  0.0114,  0.0203,  0.0516, -0.0612,  0.0473,  0.1058,
         0.0321, -0.0240, -0.0471,  0.0026, -0.0058, -0.0240, -0.0059, -0.0286,
        -0.0467, -0.0132, -0.0372, -0.0464, -0.0326,  0.0500,  0.0757,  0.0645,
         0.0174,  0.0917,  0.0282,  0.0267, -0.0618,  0.1985, -0.0636,  0.0419,
         0.0172, -0.1374,  0.0634,  0.0548,  0.0458,  0.0380, -0.0318,  0.0605,
         0.1629,  0.0465, -0.2038,  0.0078, -0.1631,  0.0563,  0.0394, -0.0589,
         0.0725, -0.0203, -0.0373, -0.0349,  0.0060,  0.0377,  0.0064,  0.0600,
        -0.0500, -0.0376,  0.0112, -0.0444, -0.0462, -0.0019,  0.0568,  0.0298,
        -0.0315, -0.0102, -0.0583,  0.0319, -0.0131, -0.0044,  0.1007,  0.0254,
         0.0099, -0.0476, -0.0426, -0.0687, -0.1354, -0.0139, -0.0215, -0.0198,
         0.0057, -0.0459,  0.0325,  0.0193, -0.0264, -0.1095,  0.0813,  0.0524,
        -0.0407, -0.0340,  0.0470, -0.0275,  0.0116, -0.0445, -0.0064, -0.0076,
         0.0368, -0.0070, -0.0101,  0.0370, -0.0162, -0.0143, -0.0341, -0.0554,
        -0.0414, -0.0575,  0.0700,  0.0350,  0.0133,  0.0751, -0.0450,  0.0404,
         0.0541,  0.0294, -0.0259, -0.0296, -0.0410, -0.0312,  0.0595, -0.0251,
        -0.0046, -0.0715, -0.0123,  0.0211,  0.0462, -0.0342,  0.0029,  0.0505,
         0.0204,  0.0006,  0.0735, -0.0474,  0.0598, -0.0247,  0.0473, -0.0121,
         0.0286,  0.0076, -0.0211,  0.0145, -0.0632,  0.0341, -0.0144, -0.0180,
         0.0049, -0.0452,  0.0353,  0.0317, -0.0376,  0.0186,  0.0446, -0.0255,
        -0.0035,  0.0449, -0.0304, -0.0291,  0.0268,  0.0415,  0.0747, -0.0073,
        -0.0210, -0.0057, -0.0390,  0.0150,  0.0588,  0.0307,  0.0512,  0.0098,
         0.0434, -0.0350, -0.0494, -0.1325,  0.0654,  0.0233, -0.0125, -0.1767,
        -0.0208, -0.0137,  0.0722,  0.0555,  0.0314,  0.0242, -0.0423, -0.0539,
        -0.0328,  0.0139, -0.0312,  0.0054,  0.0193,  0.0128,  0.0894, -0.0080,
         0.0229,  0.0170,  0.0494, -0.0165, -0.0061,  0.0148, -0.0326,  0.0557,
        -0.0348,  0.0346, -0.0749, -0.0190,  0.0529,  0.0435,  0.1021, -0.0028,
         0.0820, -0.0426, -0.0115, -0.1832,  0.0328, -0.0194, -0.1492, -0.0437,
        -0.0413, -0.0017,  0.0298, -0.0217,  0.0070, -0.0066,  0.0768, -0.0195,
        -0.0618,  0.0314,  0.1472,  0.1634, -0.0309, -0.2128, -0.0096,  0.0310,
         0.0305, -0.0333, -0.0003,  0.0274,  0.0111,  0.0110, -0.0870,  0.1873],
       device='cuda:0', requires_grad=True)]

=== Learning linear identity for dimension = 1024 ===

=== Epoch 500 ===
loss = 0.19129884
learning rate = 0.05000000
Absolute performance:
max abs err = 3.52430534
mean abs err = 0.25762394

=== Epoch 1000 ===
loss = 0.00000000
learning rate = 0.02500000
Absolute performance:
max abs err = 0.00000364
mean abs err = 0.00000064

=== Epoch 1500 ===
loss = 0.00000000
learning rate = 0.01250000
Absolute performance:
max abs err = 0.00000250
mean abs err = 0.00000037

=== Epoch 2000 ===
loss = 0.00000000
learning rate = 0.00625000
Absolute performance:
max abs err = 0.00000143
mean abs err = 0.00000022

=== Epoch 2500 ===
loss = 0.00000000
learning rate = 0.00312500
Absolute performance:
max abs err = 0.00000119
mean abs err = 0.00000015

=== Epoch 3000 ===
loss = 0.00000000
learning rate = 0.00156250
Absolute performance:
max abs err = 0.00000077
mean abs err = 0.00000010

After 3000 epochs (0:00:04 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 5.2248e-03, -8.4376e-03,  2.5612e-02,  ...,  2.0652e-02,
          2.0360e-02,  2.7024e-03],
        [ 2.3926e-02, -1.3335e-02, -2.0124e-03,  ...,  1.6762e-02,
         -1.5503e-02,  5.5965e-03],
        [-1.4061e-05,  4.3110e-04,  1.6019e-02,  ...,  1.5277e-02,
         -2.1283e-02, -2.0750e-02],
        ...,
        [ 2.3635e-02,  2.3689e-02,  1.1393e-02,  ...,  2.4116e-02,
          1.5275e-02,  3.0742e-03],
        [ 1.6903e-01,  1.0434e-02,  1.6895e-02,  ..., -1.8869e-02,
         -2.2129e-02,  4.4382e-03],
        [ 2.1681e-02,  2.0594e-02,  3.9974e-03,  ..., -8.1672e-03,
         -1.1299e-03,  1.0630e-03]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0145,  0.0274,  0.0177,  ..., -0.0279, -0.0257,  0.0392],
       device='cuda:0', requires_grad=True)]

=== Learning linear identity for dimension = 4096 ===

=== Epoch 500 ===
loss = 2.69642878
learning rate = 0.05000000
Absolute performance:
max abs err = 11.07544994
mean abs err = 1.13297486

=== Epoch 1000 ===
loss = 0.00000000
learning rate = 0.02500000
Absolute performance:
max abs err = 0.00001329
mean abs err = 0.00000170

=== Epoch 1500 ===
loss = 0.00000000
learning rate = 0.01250000
Absolute performance:
max abs err = 0.00000565
mean abs err = 0.00000075

=== Epoch 2000 ===
loss = 0.00000000
learning rate = 0.00625000
Absolute performance:
max abs err = 0.00000322
mean abs err = 0.00000035

=== Epoch 2500 ===
loss = 0.00000000
learning rate = 0.00312500
Absolute performance:
max abs err = 0.00000173
mean abs err = 0.00000019

=== Epoch 3000 ===
loss = 0.00000000
learning rate = 0.00156250
Absolute performance:
max abs err = 0.00000125
mean abs err = 0.00000012

=== Epoch 3500 ===
loss = 0.00000000
learning rate = 0.00078125
Absolute performance:
max abs err = 0.00000095
mean abs err = 0.00000008

After 3500 epochs (0:00:24 hh:mm:ss)
Learned parameters: [Parameter containing:
tensor([[ 2.4830e-03, -2.0368e-02, -1.4197e-02,  ..., -3.7317e-03,
         -1.0914e-02,  5.1241e-03],
        [ 1.4101e-01, -1.0584e-02,  1.6455e-02,  ..., -4.3521e-03,
         -1.6235e-02,  1.2015e-03],
        [-2.9378e-03,  3.9263e-03,  2.7106e-04,  ...,  1.0983e-02,
         -5.8106e-03, -3.0633e-03],
        ...,
        [-3.2500e-03, -6.8833e-03,  2.8750e-03,  ...,  3.4209e-03,
          1.3588e-04, -5.5716e-03],
        [-7.1406e-04, -4.6007e-03, -1.3821e-02,  ...,  5.9375e-03,
         -3.2893e-03,  5.6920e-03],
        [-1.3245e-02,  7.7429e-05, -1.9790e-03,  ...,  1.0520e-02,
         -9.6705e-03, -1.4027e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0069,  0.0064,  0.0024,  ...,  0.0072, -0.0009, -0.0183],
       device='cuda:0', requires_grad=True)]
